import os
import json
import time
import tracemalloc
from collections import defaultdict, Counter
from tqdm import tqdm
from tree_sitter import Language, Parser

# === å®ä½“æå–æ¨¡å— ===
from extract_entity_file import extract_file_entity
from extract_entity_variable import extract_variable_entities, extract_function_parameters
from extract_entity_function import extract_function_entities
from extract_entity_struct import extract_struct_entities
from extract_entity_field import extract_field_entities

# === å…³ç³»æå–æ¨¡å— ===
from extract_relation_calls import extract_calls_relations
from extract_relation_assignedto import extract_assigned_to_relations
from extract_relation_contains import build_file_level_contains
from extract_relation_has_members import extract_has_member_relations
from extract_relation_has_parameters import extract_has_parameter_relations
from extract_relation_has_variables import extract_has_variable_relations
from extract_relation_returns import extract_returns_relations
from extract_relation_typeof import extract_typeof_relations

# === åŒ…å«å…³ç³»æå–æ¨¡å— ===
from extract_relation_includes import extract_include_relations, build_transitive_includes, extract_extern_declarations

# === é…ç½®è·¯å¾„ ===
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
LANG_SO_PATH = os.path.join(ROOT_DIR, '..', 'build', 'my-languages.so')
OUTPUT_BASE = os.path.join(ROOT_DIR, '..', 'output')
MACRO_JSON_PATH = "/data/xuao/code_kg/data/glibc_data/macro.json"

def id_generator(start=1):
    while True:
        yield start
        start += 1

def get_parser():
    language = Language(LANG_SO_PATH, 'c')
    parser = Parser()
    parser.set_language(language)
    return parser

def get_c_files(directory):
    for root, _, files in os.walk(directory):
        for file in files:
            if file.lower().endswith(('.c', '.h')):
                yield os.path.join(root, file)

def load_macro_lookup_map(json_path):
    if not os.path.exists(json_path):
        print(f"Warning: Macro file not found: {json_path}")
        return defaultdict(list)
        
    with open(json_path, 'r') as f:
        macro_json = json.load(f)
    macro_lookup_map = defaultdict(list)
    
    # ğŸ”§ ä¿®å¤ï¼šè·å– macro.json çš„ç›®å½•ä½œä¸ºåŸºç¡€è·¯å¾„
    macro_dir = os.path.dirname(json_path)
    
    for entry in macro_json:
        relative_file = entry["file"]  # "./test_1.c"
        
        # ğŸ”§ ä¿®å¤ï¼šåŸºäº macro.json çš„ç›®å½•è§£æç›¸å¯¹è·¯å¾„
        if relative_file.startswith("./"):
            file = os.path.abspath(os.path.join(macro_dir, relative_file[2:]))
        else:
            file = os.path.abspath(os.path.join(macro_dir, relative_file))
            
        start_line, start_col, end_line, end_col = entry["location"]
        macro_lookup_map[file].append({
            "range": ((start_line, start_col), (end_line, end_col)),
            "expanded": entry["macro"],
            "original": entry["name"]
        })
    return macro_lookup_map

def build_entity_file_mapping(all_entities):
    """æ„å»ºå®ä½“IDåˆ°æ–‡ä»¶è·¯å¾„çš„æ˜ å°„"""
    entity_file_map = {}
    
    for entity in all_entities:
        if entity.get('source_file'):
            abs_path = os.path.abspath(entity['source_file'])
            entity_file_map[entity['id']] = abs_path
        elif entity.get('type') == 'FILE':
            if entity.get('source_file'):
                abs_path = os.path.abspath(entity['source_file'])
            else:
                abs_path = os.path.abspath(entity['name'])
            entity_file_map[entity['id']] = abs_path
    
    return entity_file_map

def build_file_to_entities_mapping(all_entities):
    """ğŸš€ æ–°å¢ï¼šæ„å»ºæ–‡ä»¶åˆ°å®ä½“çš„æ˜ å°„ï¼Œç”¨äºå¿«é€ŸæŸ¥æ‰¾"""
    file_to_entities = defaultdict(list)
    
    for entity in all_entities:
        if entity.get('source_file'):
            abs_path = os.path.abspath(entity['source_file'])
            file_to_entities[abs_path].append(entity)
    
    return file_to_entities

def deduplicate_relations(relations):
    """å»é‡å…³ç³»åˆ—è¡¨ - è€ƒè™‘ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    seen = set()
    unique_relations = []
    
    for rel in relations:
        # åŸºç¡€å…³ç³»é”®
        rel_key = (rel['head'], rel['tail'], rel['type'])
        
        # ğŸ†• å¦‚æœæœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŠ å…¥åˆ°é”®ä¸­
        if 'context_var_id' in rel:
            rel_key = rel_key + (rel['context_var_id'],)
        
        if rel_key not in seen:
            seen.add(rel_key)
            unique_relations.append(rel)
    
    return unique_relations

def extract_all(source_dir, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    entity_path = os.path.join(output_dir, 'entity.json')
    relation_path = os.path.join(output_dir, 'relation.json')

    id_counter = id_generator()
    parser = get_parser()

    all_entities = []
    all_relations = []

    # === æ˜ å°„è¡¨ï¼šæ”¯æŒå¤šå€¼æ˜ å°„ ===
    function_id_map = {}      # name -> [id1, id2, ...] æ”¯æŒåŒåå‡½æ•°
    variable_id_map = {}      # (name, scope) -> id æˆ– [id1, id2, ...] æ”¯æŒåŒåå…¨å±€å˜é‡
    param_id_map = {}         # (name, scope) -> id 
    struct_id_map = {}        # (name, scope) -> [id1, id2, ...] æ”¯æŒåŒåç»“æ„ä½“
    field_id_map = {}         # name -> [id1, id2, ...] 
    variable_scope_map = {}

    function_entities = []
    param_entities = []
    variable_entities = []
    struct_entities = []
    field_entities = []

    file_trees = []
    file_id_map = {}

    # === æºç ä¸å®ä¿¡æ¯è¯»å– ===
    c_files = list(get_c_files(source_dir))
    macro_lookup_map = load_macro_lookup_map(MACRO_JSON_PATH)
    print(f"âœ… è¯»å–å®å±•å¼€ä¿¡æ¯å®Œæˆï¼Œå…±åŒ…å«æ–‡ä»¶æ•°ï¼š{len(macro_lookup_map)}")

    # === é˜¶æ®µ 1ï¼šæå–æ‰€æœ‰å®ä½“ ===
    print(f"\n" + "="*60)
    print("é˜¶æ®µ 1ï¼šæå–æ‰€æœ‰å®ä½“")
    
    for source_path in tqdm(c_files, desc="é˜¶æ®µ 1ï¼šæå–å®ä½“"):
        abs_source_path = os.path.abspath(source_path)
        
        with open(abs_source_path, 'rb') as f:
            code_bytes = f.read()
        tree = parser.parse(code_bytes)
        root = tree.root_node
        file_trees.append((abs_source_path, root, code_bytes))

        file_entities, file_id = extract_file_entity(abs_source_path, id_counter)
        file_id_map[abs_source_path] = file_id
        all_entities.extend(file_entities)

        # === å‡½æ•°æ˜ å°„ï¼šæ”¯æŒåŒåå‡½æ•° ===
        functions, f_map = extract_function_entities(root, code_bytes, id_counter)
        for e in functions: 
            e["source_file"] = abs_source_path
        function_entities.extend(functions)
        
        for func_name, func_id in f_map.items():
            function_id_map.setdefault(func_name, []).append(func_id)

        # === ç»“æ„ä½“æ˜ å°„ï¼šæ”¯æŒåŒåç»“æ„ä½“ ===
        structs, s_map = extract_struct_entities(root, code_bytes, id_counter)
        for e in structs: 
            e["source_file"] = abs_source_path
        struct_entities.extend(structs)
        
        for struct_key, struct_id in s_map.items():
            struct_id_map.setdefault(struct_key, []).append(struct_id)

        # === å˜é‡æ˜ å°„ï¼šæ”¯æŒåŒåå…¨å±€å˜é‡ ===
        variables, v_map, scope_map = extract_variable_entities(root, code_bytes, id_counter)
        for e in variables: 
            e["source_file"] = abs_source_path
        variable_entities.extend(variables)
        variable_scope_map.update(scope_map)

        # å…³é”®ä¿®å¤ï¼šå˜é‡æ˜ å°„æ”¯æŒå¤šå€¼
        for var_key, var_id in v_map.items():
            var_name, var_scope = var_key
            
            # å…¨å±€å˜é‡æ”¯æŒå¤šå€¼æ˜ å°„ï¼ˆå¯èƒ½åŒåï¼‰
            if var_scope == 'global':
                if var_key in variable_id_map:
                    existing = variable_id_map[var_key]
                    if isinstance(existing, list):
                        existing.append(var_id)
                    else:
                        variable_id_map[var_key] = [existing, var_id]
                else:
                    variable_id_map[var_key] = var_id
            else:
                # å±€éƒ¨å˜é‡é€šå¸¸ä¸ä¼šå†²çªï¼Œä¿æŒå•å€¼æ˜ å°„
                variable_id_map[var_key] = var_id

        # === å‚æ•°æ˜ å°„ ===
        params, p_map = extract_function_parameters(root, code_bytes, id_counter, f_map)
        for e in params: 
            e["source_file"] = abs_source_path
        param_entities.extend(params)
        param_id_map.update(p_map)

        # === å­—æ®µæ˜ å°„ ===
        fields, f_map2 = extract_field_entities(root, code_bytes, id_counter, s_map)
        for e in fields: 
            e["source_file"] = abs_source_path
        field_entities.extend(fields)
        for name, ids in f_map2.items():
            field_id_map.setdefault(name, []).extend(ids)

    all_entities.extend(function_entities + struct_entities + variable_entities + param_entities + field_entities)

    # === ğŸš€ ä¼˜åŒ–ï¼šé¢„è®¡ç®—æ˜ å°„è¡¨ï¼Œæå‰å®Œæˆé™æ€å…³ç³»å‡†å¤‡ ===
    print(f"\n" + "="*60)
    print("é¢„è®¡ç®—æ˜ å°„è¡¨...")
    
    # æ„å»ºå®ä½“æ–‡ä»¶æ˜ å°„
    entity_file_map = build_entity_file_mapping(all_entities)
    
    # ğŸš€ å…³é”®ä¼˜åŒ–ï¼šæ„å»ºæ–‡ä»¶åˆ°å®ä½“çš„åå‘æ˜ å°„
    file_to_entities = build_file_to_entities_mapping(all_entities)
    print(f"âœ… æ–‡ä»¶-å®ä½“æ˜ å°„å®Œæˆï¼Œè¦†ç›– {len(file_to_entities)} ä¸ªæ–‡ä»¶")

    # === é˜¶æ®µ 2ï¼šæ–‡ä»¶å¯è§æ€§æ˜ å°„å’Œincludeå…³ç³» ===
    print(f"\n" + "="*60)
    print("é˜¶æ®µ 2ï¼šæ„å»ºæ–‡ä»¶å¯è§æ€§æ˜ å°„...")
    
    # æå–æ‰€æœ‰includeå…³ç³»å’Œexternå£°æ˜
    all_include_relations = []
    all_extern_functions = set()

    # ä½¿ç”¨ä¼˜åŒ–åçš„BFSç®—æ³•è¿›è¡Œå¯è§æ€§è®¡ç®—
    for source_path, root, code_bytes in tqdm(file_trees, desc="æ„å»ºå¯è§æ€§æ˜ å°„"):
        include_rels, direct_includes = extract_include_relations(root, code_bytes, file_id_map, source_path)
        all_include_relations.extend(include_rels)
        
        extern_funcs = extract_extern_declarations(root, code_bytes)
        all_extern_functions.update(extern_funcs)

    # æ„å»ºä¼ é€’åŒ…å«å…³ç³»ï¼ˆæ–‡ä»¶å¯è§æ€§æ˜ å°„ï¼‰
    file_visibility = build_transitive_includes(all_include_relations, file_id_map)

    all_relations.extend(all_include_relations)
    print(f"âœ… æå–åˆ° {len(all_include_relations)} ä¸ª INCLUDES å…³ç³»")
    print(f"âœ… è¯†åˆ«åˆ° {len(all_extern_functions)} ä¸ª extern å‡½æ•°å£°æ˜")

    # === é˜¶æ®µ 3ï¼šä¼˜åŒ–åçš„é™æ€å…³ç³»æå– ===
    print(f"\n" + "="*60)
    print("é˜¶æ®µ 3ï¼šé™æ€å…³ç³»ï¼ˆåŒ…å«/æˆå‘˜ï¼‰...")

    # ğŸš€ ä¼˜åŒ–ï¼šä½¿ç”¨é¢„è®¡ç®—çš„æ˜ å°„ç›´æ¥ç”ŸæˆCONTAINSå…³ç³»
    for source_path in tqdm(c_files, desc="é˜¶æ®µ 3ï¼šCONTAINSå…³ç³»"):
        abs_path = os.path.abspath(source_path)
        file_id = file_id_map.get(abs_path)
        if file_id is None:
            continue
        
        # ğŸš€ ä¼˜åŒ–ï¼šO(1)æŸ¥æ‰¾æ›¿ä»£O(N)éå†
        entities_in_file = file_to_entities.get(abs_path, [])
        
        # è¿‡æ»¤éœ€è¦çš„å®ä½“ç±»å‹
        contain_list = [
            entity for entity in entities_in_file
            if (entity['type'] in ('FUNCTION', 'STRUCT') or 
                (entity['type'] == 'VARIABLE' and entity.get('scope') == 'global'))
        ]
        
        if contain_list:  # åªæœ‰åœ¨æœ‰å®ä½“æ—¶æ‰åˆ›å»ºå…³ç³»
            rels = build_file_level_contains(file_id, contain_list)
            all_relations.extend(rels)

    # HAS_MEMBERå…³ç³»æå–
    print(f"\næå– HAS_MEMBER å…³ç³»...")
    rels = extract_has_member_relations(field_entities, struct_id_map)
    all_relations.extend(rels)

    # HAS_PARAMETER  
    rels = extract_has_parameter_relations(param_entities, function_id_map)
    all_relations.extend(rels)

    # HAS_VARIABLE
    rels = extract_has_variable_relations(variable_entities, function_id_map)
    all_relations.extend(rels)

    # === é˜¶æ®µ 4ï¼šå‡½æ•°è°ƒç”¨å…³ç³» ===
    print(f"\n" + "="*60)
    print("é˜¶æ®µ 4ï¼šæå– CALLS å…³ç³»...")

    for source_path, root, code_bytes in tqdm(file_trees, desc="é˜¶æ®µ 4ï¼šæå– CALLS"):
        rels = extract_calls_relations(
            root, code_bytes, function_id_map, {**variable_id_map, **param_id_map}, field_id_map,
            source_path, file_visibility, entity_file_map, all_extern_functions, macro_lookup_map, source_path, all_entities
        )
        all_relations.extend(rels)

    # === é˜¶æ®µ 5ï¼šèµ‹å€¼å…³ç³» ===
    print(f"\n" + "="*60)
    print("é˜¶æ®µ 5ï¼šæå– ASSIGNED_TO å…³ç³»...")
    
    for source_path, root, code_bytes in tqdm(file_trees, desc="é˜¶æ®µ 5ï¼šæå– ASSIGNED_TO"):
        rels = extract_assigned_to_relations(
            root, code_bytes, function_id_map, {**variable_id_map, **param_id_map}, field_id_map,
            source_path, file_visibility, entity_file_map, all_extern_functions, macro_lookup_map, source_path
        )
        all_relations.extend(rels)

    # === é˜¶æ®µ 6ï¼šè¯­ä¹‰å…³ç³» ===
    print(f"\n" + "="*60)
    print("é˜¶æ®µ 6ï¼šæå– RETURNS / TYPE_OF...")
    
    for source_path, root, code_bytes in tqdm(file_trees, desc="é˜¶æ®µ 6ï¼šæå– RETURNS / TYPE_OF"):
        # RETURNS
        rels = extract_returns_relations(
            root, code_bytes, function_id_map, {**variable_id_map, **param_id_map}, field_id_map,
            source_path, file_visibility, entity_file_map
        )
        all_relations.extend(rels)

        # TYPE_OF
        rels = extract_typeof_relations(
            root, code_bytes, variable_entities + param_entities, field_entities, struct_id_map,
            source_path, file_visibility, entity_file_map
        )
        all_relations.extend(rels)

    # æ¸…ç†å†…å­˜
    del file_trees
    del file_to_entities

    # === æœ€ç»ˆå»é‡å’Œç»Ÿè®¡ ===
    print(f"\n" + "="*60)
    print("å»é‡å…³ç³»...")
    original_count = len(all_relations)
    all_relations = deduplicate_relations(all_relations)
    deduplicated_count = len(all_relations)
    print(f"âœ… å»é‡å®Œæˆï¼š{original_count} -> {deduplicated_count} (ç§»é™¤ {original_count - deduplicated_count} ä¸ªé‡å¤)")

    # === è¾“å‡º JSON ===
    with open(entity_path, 'w') as f:
        json.dump(all_entities, f, indent=2)
    with open(relation_path, 'w') as f:
        json.dump(all_relations, f, indent=2)

    print(f"\nâœ… æå–å®Œæˆï¼šå®ä½“ {len(all_entities)} ä¸ªï¼Œå…³ç³» {len(all_relations)} æ¡ã€‚")
    
    # å…³ç³»ç»Ÿè®¡
    relation_types = Counter([r['type'] for r in all_relations])
    print(f"\nå…³ç³»ç±»å‹ç»Ÿè®¡ï¼š")
    for k, v in relation_types.items():
        print(f"  - {k}: {v}")
    
    # å¯è§æ€§æ£€æŸ¥ç»Ÿè®¡
    visibility_checked = sum(1 for r in all_relations if r.get('visibility_checked'))
    print(f"\nå¯è§æ€§æ£€æŸ¥è¦†ç›–ï¼š{visibility_checked}/{len(all_relations)} ({visibility_checked/len(all_relations)*100:.1f}%)")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--source", type=str, required=True, help="C æºç ç›®å½•è·¯å¾„")
    parser.add_argument("--output", type=str, required=True, help="è¾“å‡ºç›®å½•è·¯å¾„")
    args = parser.parse_args()

    tracemalloc.start()
    start_time = time.time()
    extract_all(args.source, args.output)
    current, peak = tracemalloc.get_traced_memory()
    end_time = time.time()
    print(f"\næ€»è€—æ—¶ï¼š{end_time - start_time:.2f} ç§’")
    print(f"å½“å‰å†…å­˜ï¼š{current / 1024 / 1024:.2f} MBï¼›å³°å€¼ï¼š{peak / 1024 / 1024:.2f} MB")
    tracemalloc.stop()
