#!/usr/bin/env python3
"""
MMCé©±åŠ¨ä»£ç çŸ¥è¯†å›¾è°±æå–å·¥å…·

ä¸“é—¨ç”¨äºæå– Linux drivers/mmc å­ç³»ç»Ÿçš„ä»£ç çŸ¥è¯†å›¾è°±
æºç è·¯å¾„: /data/xuao/code_kg/data/linux_data/drivers/mmc
è¾“å‡ºè·¯å¾„: output/mmc/
"""

import os
import json
import time
import tracemalloc
from collections import defaultdict, Counter
from tqdm import tqdm
from tree_sitter import Language, Parser

# === å®ä½“æå–æ¨¡å— ===
from extract_entity_file import extract_file_entity
from extract_entity_variable import extract_variable_entities, extract_function_parameters
from extract_entity_function import extract_function_entities
from extract_entity_struct import extract_struct_entities
from extract_entity_field import extract_field_entities

# === å…³ç³»æå–æ¨¡å— ===
from extract_relation_calls import extract_calls_relations
from extract_relation_assignedto import extract_assigned_to_relations
from extract_relation_contains import build_file_level_contains
from extract_relation_has_members import extract_has_member_relations
from extract_relation_has_parameters import extract_has_parameter_relations
from extract_relation_has_variables import extract_has_variable_relations
from extract_relation_returns import extract_returns_relations
from extract_relation_typeof import extract_typeof_relations

# === åŒ…å«å…³ç³»æå–æ¨¡å— ===
from extract_relation_includes import extract_include_relations, build_transitive_includes, extract_extern_declarations

# === MMC ä¸“ç”¨é…ç½®è·¯å¾„ ===
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
LANG_SO_PATH = os.path.join(ROOT_DIR, '..', 'build', 'my-languages.so')

# MMC é©±åŠ¨æºç è·¯å¾„ï¼ˆå›ºå®šï¼‰
MMC_SOURCE_DIR = "/data/xuao/code_kg/data/linux_data/drivers/mmc"

# MMC è¾“å‡ºè·¯å¾„ï¼ˆå›ºå®šï¼‰
MMC_OUTPUT_DIR = os.path.join(ROOT_DIR, '..', 'output', 'mmc')

# MMC å®å±•å¼€ä¿¡æ¯è·¯å¾„ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
MMC_MACRO_JSON_PATH = "/data/xuao/code_kg/data/linux_data/drivers/mmc/macro.json"

def id_generator(start=1):
    """IDç”Ÿæˆå™¨"""
    while True:
        yield start
        start += 1

def get_parser():
    """åˆå§‹åŒ–Tree-sitterè§£æå™¨"""
    language = Language(LANG_SO_PATH, 'c')
    parser = Parser()
    parser.set_language(language)
    return parser

def get_c_files(directory):
    """é€’å½’è·å–ç›®å½•ä¸‹æ‰€æœ‰.cå’Œ.hæ–‡ä»¶"""
    c_files = []
    for root, _, files in os.walk(directory):
        for file in files:
            if file.lower().endswith(('.c', '.h')):
                c_files.append(os.path.join(root, file))
    return c_files

def load_macro_lookup_map(json_path):
    """åŠ è½½å®å±•å¼€ä¿¡æ¯"""
    if not os.path.exists(json_path):
        print(f"âš ï¸  å®æ–‡ä»¶æœªæ‰¾åˆ°: {json_path}")
        print(f"   å°†è·³è¿‡å®å±•å¼€åˆ†æï¼Œç»§ç»­æå–å…¶ä»–ä¿¡æ¯...")
        return defaultdict(list)

    with open(json_path, 'r') as f:
        macro_json = json.load(f)
    macro_lookup_map = defaultdict(list)

    macro_dir = os.path.dirname(json_path)

    for entry in macro_json:
        relative_file = entry["file"]

        if relative_file.startswith("./"):
            file = os.path.abspath(os.path.join(macro_dir, relative_file[2:]))
        else:
            file = os.path.abspath(os.path.join(macro_dir, relative_file))

        start_line, start_col, end_line, end_col = entry["location"]
        macro_lookup_map[file].append({
            "range": ((start_line, start_col), (end_line, end_col)),
            "expanded": entry["macro"],
            "original": entry["name"]
        })

    print(f"âœ… è¯»å–å®å±•å¼€ä¿¡æ¯å®Œæˆï¼Œå…±åŒ…å«æ–‡ä»¶æ•°ï¼š{len(macro_lookup_map)}")
    return macro_lookup_map

def build_entity_file_mapping(all_entities):
    """æ„å»ºå®ä½“IDåˆ°æ–‡ä»¶è·¯å¾„çš„æ˜ å°„"""
    entity_file_map = {}

    for entity in all_entities:
        if entity.get('source_file'):
            abs_path = os.path.abspath(entity['source_file'])
            entity_file_map[entity['id']] = abs_path
        elif entity.get('type') == 'FILE':
            if entity.get('source_file'):
                abs_path = os.path.abspath(entity['source_file'])
            else:
                abs_path = os.path.abspath(entity['name'])
            entity_file_map[entity['id']] = abs_path

    return entity_file_map

def build_file_to_entities_mapping(all_entities):
    """æ„å»ºæ–‡ä»¶åˆ°å®ä½“çš„æ˜ å°„ï¼Œç”¨äºå¿«é€ŸæŸ¥æ‰¾"""
    file_to_entities = defaultdict(list)

    for entity in all_entities:
        if entity.get('source_file'):
            abs_path = os.path.abspath(entity['source_file'])
            file_to_entities[abs_path].append(entity)

    return file_to_entities

def deduplicate_relations(relations):
    """å»é‡å…³ç³»åˆ—è¡¨ - è€ƒè™‘ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    seen = set()
    unique_relations = []

    for rel in relations:
        # åŸºç¡€å…³ç³»é”®
        rel_key = (rel['head'], rel['tail'], rel['type'])

        # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŠ å…¥åˆ°é”®ä¸­
        if 'context_var_id' in rel:
            rel_key = rel_key + (rel['context_var_id'],)

        if rel_key not in seen:
            seen.add(rel_key)
            unique_relations.append(rel)

    return unique_relations

def extract_mmc_knowledge_graph():
    """æå–MMCé©±åŠ¨çš„ä»£ç çŸ¥è¯†å›¾è°±"""

    print("=" * 80)
    print("MMC é©±åŠ¨ä»£ç çŸ¥è¯†å›¾è°±æå–å·¥å…·")
    print("=" * 80)
    print(f"ğŸ“‚ æºç è·¯å¾„: {MMC_SOURCE_DIR}")
    print(f"ğŸ“ è¾“å‡ºè·¯å¾„: {MMC_OUTPUT_DIR}")
    print("=" * 80)

    # æ£€æŸ¥æºç ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(MMC_SOURCE_DIR):
        print(f"âŒ é”™è¯¯ï¼šæºç ç›®å½•ä¸å­˜åœ¨: {MMC_SOURCE_DIR}")
        print(f"   è¯·ç¡®ä¿å·²æ­£ç¡®æŒ‚è½½æˆ–ä¸‹è½½ Linux æºç ")
        return

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(MMC_OUTPUT_DIR, exist_ok=True)
    entity_path = os.path.join(MMC_OUTPUT_DIR, 'entity.json')
    relation_path = os.path.join(MMC_OUTPUT_DIR, 'relation.json')

    id_counter = id_generator()
    parser = get_parser()

    all_entities = []
    all_relations = []

    # === æ˜ å°„è¡¨ï¼šæ”¯æŒå¤šå€¼æ˜ å°„ ===
    function_id_map = {}
    variable_id_map = {}
    param_id_map = {}
    struct_id_map = {}
    field_id_map = {}
    variable_scope_map = {}

    function_entities = []
    param_entities = []
    variable_entities = []
    struct_entities = []
    field_entities = []

    file_trees = []
    file_id_map = {}

    # === è·å–æ‰€æœ‰Cæ–‡ä»¶ ===
    c_files = get_c_files(MMC_SOURCE_DIR)
    print(f"\nğŸ“Š æ‰¾åˆ° {len(c_files)} ä¸ªC/Hæ–‡ä»¶")

    if len(c_files) == 0:
        print(f"âŒ é”™è¯¯ï¼šæœªåœ¨ {MMC_SOURCE_DIR} æ‰¾åˆ°ä»»ä½•C/Hæ–‡ä»¶")
        return

    # æ˜¾ç¤ºéƒ¨åˆ†æ–‡ä»¶è·¯å¾„ç¤ºä¾‹
    print(f"\nç¤ºä¾‹æ–‡ä»¶è·¯å¾„ï¼š")
    for f in c_files[:5]:
        print(f"  - {f}")
    if len(c_files) > 5:
        print(f"  ... è¿˜æœ‰ {len(c_files) - 5} ä¸ªæ–‡ä»¶")

    # === åŠ è½½å®ä¿¡æ¯ ===
    macro_lookup_map = load_macro_lookup_map(MMC_MACRO_JSON_PATH)

    # === é˜¶æ®µ 1ï¼šæå–æ‰€æœ‰å®ä½“ ===
    print(f"\n" + "="*80)
    print("é˜¶æ®µ 1ï¼šæå–æ‰€æœ‰å®ä½“")
    print("="*80)

    for source_path in tqdm(c_files, desc="æå–å®ä½“"):
        abs_source_path = os.path.abspath(source_path)

        try:
            with open(abs_source_path, 'rb') as f:
                code_bytes = f.read()
        except Exception as e:
            print(f"\nâš ï¸  è·³è¿‡æ–‡ä»¶ {abs_source_path}: {e}")
            continue

        tree = parser.parse(code_bytes)
        root = tree.root_node
        file_trees.append((abs_source_path, root, code_bytes))

        file_entities, file_id = extract_file_entity(abs_source_path, id_counter)
        file_id_map[abs_source_path] = file_id
        all_entities.extend(file_entities)

        # === å‡½æ•°æå– ===
        functions, f_map = extract_function_entities(root, code_bytes, id_counter)
        for e in functions:
            e["source_file"] = abs_source_path
        function_entities.extend(functions)

        for func_name, func_id in f_map.items():
            function_id_map.setdefault(func_name, []).append(func_id)

        # === ç»“æ„ä½“æå– ===
        structs, s_map = extract_struct_entities(root, code_bytes, id_counter)
        for e in structs:
            e["source_file"] = abs_source_path
        struct_entities.extend(structs)

        for struct_key, struct_id in s_map.items():
            struct_id_map.setdefault(struct_key, []).append(struct_id)

        # === å˜é‡æå– ===
        variables, v_map, scope_map = extract_variable_entities(root, code_bytes, id_counter)
        for e in variables:
            e["source_file"] = abs_source_path
        variable_entities.extend(variables)
        variable_scope_map.update(scope_map)

        for var_key, var_id in v_map.items():
            var_name, var_scope = var_key

            if var_scope == 'global':
                if var_key in variable_id_map:
                    existing = variable_id_map[var_key]
                    if isinstance(existing, list):
                        existing.append(var_id)
                    else:
                        variable_id_map[var_key] = [existing, var_id]
                else:
                    variable_id_map[var_key] = var_id
            else:
                variable_id_map[var_key] = var_id

        # === å‚æ•°æå– ===
        params, p_map = extract_function_parameters(root, code_bytes, id_counter, f_map)
        for e in params:
            e["source_file"] = abs_source_path
        param_entities.extend(params)
        param_id_map.update(p_map)

        # === å­—æ®µæå– ===
        fields, f_map2 = extract_field_entities(root, code_bytes, id_counter, s_map)
        for e in fields:
            e["source_file"] = abs_source_path
        field_entities.extend(fields)
        for name, ids in f_map2.items():
            field_id_map.setdefault(name, []).extend(ids)

    all_entities.extend(function_entities + struct_entities + variable_entities + param_entities + field_entities)

    print(f"\nâœ… å®ä½“æå–å®Œæˆï¼š")
    print(f"   - æ–‡ä»¶ï¼š{len(file_id_map)}")
    print(f"   - å‡½æ•°ï¼š{len(function_entities)}")
    print(f"   - ç»“æ„ä½“ï¼š{len(struct_entities)}")
    print(f"   - å˜é‡ï¼š{len(variable_entities)}")
    print(f"   - å‚æ•°ï¼š{len(param_entities)}")
    print(f"   - å­—æ®µï¼š{len(field_entities)}")

    # === é¢„è®¡ç®—æ˜ å°„è¡¨ ===
    print(f"\n" + "="*80)
    print("é¢„è®¡ç®—æ˜ å°„è¡¨...")

    entity_file_map = build_entity_file_mapping(all_entities)
    file_to_entities = build_file_to_entities_mapping(all_entities)
    print(f"âœ… æ–‡ä»¶-å®ä½“æ˜ å°„å®Œæˆï¼Œè¦†ç›– {len(file_to_entities)} ä¸ªæ–‡ä»¶")

    # === é˜¶æ®µ 2ï¼šæ–‡ä»¶å¯è§æ€§æ˜ å°„å’Œincludeå…³ç³» ===
    print(f"\n" + "="*80)
    print("é˜¶æ®µ 2ï¼šæ„å»ºæ–‡ä»¶å¯è§æ€§æ˜ å°„")
    print("="*80)

    all_include_relations = []
    all_extern_functions = set()

    for source_path, root, code_bytes in tqdm(file_trees, desc="æ„å»ºå¯è§æ€§æ˜ å°„"):
        include_rels, direct_includes = extract_include_relations(root, code_bytes, file_id_map, source_path)
        all_include_relations.extend(include_rels)

        extern_funcs = extract_extern_declarations(root, code_bytes)
        all_extern_functions.update(extern_funcs)

    file_visibility = build_transitive_includes(all_include_relations, file_id_map)

    all_relations.extend(all_include_relations)
    print(f"âœ… æå–åˆ° {len(all_include_relations)} ä¸ª INCLUDES å…³ç³»")
    print(f"âœ… è¯†åˆ«åˆ° {len(all_extern_functions)} ä¸ª extern å‡½æ•°å£°æ˜")

    # === é˜¶æ®µ 3ï¼šé™æ€å…³ç³»æå– ===
    print(f"\n" + "="*80)
    print("é˜¶æ®µ 3ï¼šé™æ€å…³ç³»ï¼ˆåŒ…å«/æˆå‘˜ï¼‰")
    print("="*80)

    for source_path in tqdm(c_files, desc="CONTAINSå…³ç³»"):
        abs_path = os.path.abspath(source_path)
        file_id = file_id_map.get(abs_path)
        if file_id is None:
            continue

        entities_in_file = file_to_entities.get(abs_path, [])

        contain_list = [
            entity for entity in entities_in_file
            if (entity['type'] in ('FUNCTION', 'STRUCT') or
                (entity['type'] == 'VARIABLE' and entity.get('scope') == 'global'))
        ]

        if contain_list:
            rels = build_file_level_contains(file_id, contain_list)
            all_relations.extend(rels)

    # HAS_MEMBERå…³ç³»
    print(f"\næå– HAS_MEMBER å…³ç³»...")
    rels = extract_has_member_relations(field_entities, struct_id_map)
    all_relations.extend(rels)

    # HAS_PARAMETER
    rels = extract_has_parameter_relations(param_entities, function_id_map)
    all_relations.extend(rels)

    # HAS_VARIABLE
    rels = extract_has_variable_relations(variable_entities, function_id_map)
    all_relations.extend(rels)

    # === é˜¶æ®µ 4ï¼šå‡½æ•°è°ƒç”¨å…³ç³» ===
    print(f"\n" + "="*80)
    print("é˜¶æ®µ 4ï¼šæå– CALLS å…³ç³»")
    print("="*80)

    for source_path, root, code_bytes in tqdm(file_trees, desc="æå– CALLS"):
        rels = extract_calls_relations(
            root, code_bytes, function_id_map, {**variable_id_map, **param_id_map}, field_id_map,
            source_path, file_visibility, entity_file_map, all_extern_functions, macro_lookup_map, source_path, all_entities
        )
        all_relations.extend(rels)

    # === é˜¶æ®µ 5ï¼šèµ‹å€¼å…³ç³» ===
    print(f"\n" + "="*80)
    print("é˜¶æ®µ 5ï¼šæå– ASSIGNED_TO å…³ç³»")
    print("="*80)

    for source_path, root, code_bytes in tqdm(file_trees, desc="æå– ASSIGNED_TO"):
        rels = extract_assigned_to_relations(
            root, code_bytes, function_id_map, {**variable_id_map, **param_id_map}, field_id_map,
            source_path, file_visibility, entity_file_map, all_extern_functions, macro_lookup_map, source_path
        )
        all_relations.extend(rels)

    # === é˜¶æ®µ 6ï¼šè¯­ä¹‰å…³ç³» ===
    print(f"\n" + "="*80)
    print("é˜¶æ®µ 6ï¼šæå– RETURNS / TYPE_OF")
    print("="*80)

    for source_path, root, code_bytes in tqdm(file_trees, desc="æå– RETURNS / TYPE_OF"):
        # RETURNS
        rels = extract_returns_relations(
            root, code_bytes, function_id_map, {**variable_id_map, **param_id_map}, field_id_map,
            source_path, file_visibility, entity_file_map
        )
        all_relations.extend(rels)

        # TYPE_OF
        rels = extract_typeof_relations(
            root, code_bytes, variable_entities + param_entities, field_entities, struct_id_map,
            source_path, file_visibility, entity_file_map
        )
        all_relations.extend(rels)

    # æ¸…ç†å†…å­˜
    del file_trees
    del file_to_entities

    # === æœ€ç»ˆå»é‡å’Œç»Ÿè®¡ ===
    print(f"\n" + "="*80)
    print("å»é‡å…³ç³»...")
    original_count = len(all_relations)
    all_relations = deduplicate_relations(all_relations)
    deduplicated_count = len(all_relations)
    print(f"âœ… å»é‡å®Œæˆï¼š{original_count} -> {deduplicated_count} (ç§»é™¤ {original_count - deduplicated_count} ä¸ªé‡å¤)")

    # === è¾“å‡º JSON ===
    print(f"\n" + "="*80)
    print("ä¿å­˜ç»“æœ...")

    with open(entity_path, 'w', encoding='utf-8') as f:
        json.dump(all_entities, f, indent=2, ensure_ascii=False)
    with open(relation_path, 'w', encoding='utf-8') as f:
        json.dump(all_relations, f, indent=2, ensure_ascii=False)

    print(f"\n" + "="*80)
    print("âœ… MMC é©±åŠ¨çŸ¥è¯†å›¾è°±æå–å®Œæˆï¼")
    print("="*80)
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
    print(f"   - å®ä½“æ€»æ•°ï¼š{len(all_entities)}")
    print(f"   - å…³ç³»æ€»æ•°ï¼š{len(all_relations)}")
    print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶ï¼š")
    print(f"   - å®ä½“æ–‡ä»¶ï¼š{entity_path}")
    print(f"   - å…³ç³»æ–‡ä»¶ï¼š{relation_path}")

    # å…³ç³»ç±»å‹ç»Ÿè®¡
    relation_types = Counter([r['type'] for r in all_relations])
    print(f"\nğŸ“ˆ å…³ç³»ç±»å‹ç»Ÿè®¡ï¼š")
    for k, v in sorted(relation_types.items(), key=lambda x: x[1], reverse=True):
        print(f"   - {k:20s}: {v:6d}")

    # å¯è§æ€§æ£€æŸ¥ç»Ÿè®¡
    visibility_checked = sum(1 for r in all_relations if r.get('visibility_checked'))
    print(f"\nğŸ” å¯è§æ€§æ£€æŸ¥è¦†ç›–ï¼š{visibility_checked}/{len(all_relations)} ({visibility_checked/len(all_relations)*100:.1f}%)")
    print("="*80)

if __name__ == "__main__":
    tracemalloc.start()
    start_time = time.time()

    try:
        extract_mmc_knowledge_graph()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        print(f"\n\nâŒ æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        current, peak = tracemalloc.get_traced_memory()
        end_time = time.time()
        print(f"\nâ±ï¸  æ€»è€—æ—¶ï¼š{end_time - start_time:.2f} ç§’")
        print(f"ğŸ’¾ å†…å­˜ä½¿ç”¨ï¼šå½“å‰ {current / 1024 / 1024:.2f} MBï¼›å³°å€¼ {peak / 1024 / 1024:.2f} MB")
        tracemalloc.stop()
